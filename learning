#!./.venv/bin/python

import click, os
from datetime import datetime


# Example
# --------
#
# FILE_SIZE=245,35 SAMPLE_COUNT=100 BATCH_SIZE=128 LABEL_COUNT=100 ./learning env
#
FILE_SIZE = tuple(map(int, os.getenv("FILE_SIZE", "254,254").split(",")))
SAMPLE_COUNT = int(os.getenv("SAMPLE_COUNT", 50))
BATCH_SIZE = int(os.getenv("BATCH_SIZE", 32))
LABEL_COUNT = int(os.getenv("PD_LABEL_COUNT", 5))


@click.group()
def cli():
    pass


@click.command()
def env():
    print(type(FILE_SIZE))
    print(f"FILE_SIZE={FILE_SIZE}")
    print(f"SAMPLE_COUNT={SAMPLE_COUNT}")
    print(f"BATCH_SIZE={BATCH_SIZE}")
    print(f"LABEL_COUNT={LABEL_COUNT}")


@click.command()
@click.option("--folder_name", required=True)
@click.option("--model_file", required=True)
def predict_folder(folder_name, model_file):
    """
    Predicts the labels of a image set given a dataframe
    
    Example
    -------
    ./learning predict-folder \
        --folder_name flower_photos \
        --model_file models/flowers_photos/vgg19/20230918180525_folder_vgg19/model.keras
    """
    from source.cnn.generators.folder_generator import FolderGenerator
    from source.cnn.bases.factory import Factory
    from source.cnn.predictor import Predictor
    from source.cnn.graphics.confussion_matrix import ConfusionMatrix
    from source.cnn.graphics.classification_report import ClassificationReport
    import json, re

    r = model_file.split("/")
    model_name = r[1]
    model_folder = "/".join(r[:-1])
    version = re.findall("\d+", r[2])[0]

    base = Factory.build(model_name, FILE_SIZE)

    gen = FolderGenerator(base.preprocess_input_method())
    generator = gen.generator(
        "valid",
        f"{folder_name}/test",
        target_size=FILE_SIZE,
        batch_size=BATCH_SIZE,
    )

    pred = Predictor(
        n_class=LABEL_COUNT,
        batch_size=BATCH_SIZE,
        target_file_size_shape=FILE_SIZE,
    )
    pred.load(model_file)
    pred.predict(generator)

    pred.classification_report(to_file=f"{model_folder}/classification_report.txt")
    pred.confusion_matrix(to_file=f"{model_folder}/confusion_matrix.json")

    ClassificationReport(
        open(f"{model_folder}/classification_report.txt", "r").read(),
        model_name,
        subtitle=f"Project Flowers Photos version {version}",
    ).render().save(f"{model_folder}/classification_report.jpg")

    f = open(f"{model_folder}/confusion_matrix.json", "r").read()

    ConfusionMatrix(
        json.loads(f)["matrix"],
        model_name,
        subtitle=f"Project Flowers Photos version {version}",
    ).render().save(f"{model_folder}/confusion_matrix.jpg")


@click.command()
@click.option("--dataframe", required=True)
@click.option("--model_file", required=True)
def predict_dataset(dataframe, model_file):
    """
    Predicts the labels of a image set given a dataframe
    """
    from source.cnn.generators.folder_generator import DataSetGenerator
    from source.cnn.bases.factory import Factory
    from source.cnn.predictor import Predictor

    base = Factory.build(model_name, FILE_SIZE)

    dataset = ImageDataSet(dataframe, "image_lien", "label", sample_count=SAMPLE_COUNT)
    dataset.load()
    dataset.find_n_top_labels(LABEL_COUNT)
    dataset.downsample_to_equal()
    _, test = dataset.split_sample(0.2)

    gen = DataSetGenerator(base.preprocess_input_method())
    generator = gen.generator(
        "test",
        test,
        "input/images",
        target_size=FILE_SIZE,
        batch_size=BATCH_SIZE,
    )

    pred = Predictor(
        n_class=LABEL_COUNT,
        batch_size=BATCH_SIZE,
        target_file_size_shape=FILE_SIZE,
    )
    pred.load(model_file)
    pred.predict(generator)

    print(pred.classification_report())
    print(pred.confusion_matrix())


@click.command()
@click.option("--folder_name", required=True)
@click.option("--model_name", required=True)
@click.option("--architecture", required=False)
def train_folder(folder_name, model_name, architecture="a"):
    """Trains a model in a giving Image Dataset in a folder.
    Images insde the folder must be separated in train, valid
    and test subfolders by desired proportions.
    Images must be separated in subfolders with the name
    of the label.

    Args:
        folder_name (str): Folder with images
        model_name (str): base model name Ex: 'vgg16'
        architecture (str): CNN Architecture to run the training. (a, b or c)
    """
    from source.cnn.project import ImageProject, Training

    if model_name == "all":
        model_name = [
            "vgg16",
            "vgg19",
            "resnet50",
            "efficientNetB1",
            "efficientNetB5",
            "efficientNetB7",
        ]
    else:
        model_name = [model_name]

    if architecture == None:
        architecture = "a"

    project = ImageProject(
        folder_name.split("/")[-1],
        folder_name,
        file_size=FILE_SIZE,
        batch_size=BATCH_SIZE,
        architecture=architecture,
    )
    for modeln in model_name:
        project.create_model_folder(folder_name.split("/")[-1], architecture, modeln)
    project.train(model_name)


@click.command()
@click.option("--dataframe", required=True)
@click.option("--model_name", required=True)
def train_dataset(dataframe, model_name):
    from dask.distributed import Client, progress
    import joblib

    from source.logger import Logger as CNNLogger
    from source.cnn.architectures.ach_a import AchA as Architecture
    from source.cnn.bases.factory import Factory
    from source.cnn.generators.dataset_generator import DataSetGenerator
    from source.cnn.trainer import Trainer

    model_output = create_model_folder(
        model_name, f"{datetime.now().strftime('%Y%m%d%H%M%S')}_df_{model_name}"
    )

    output_report = f"{model_output}/report.txt"

    logger = (
        CNNLogger(output_report, logger_name="CNN Images by Dataset")
    ).get_logger()

    logger.info("Creating an instance of CNN Logger\n\n")
    base = Factory.build(model_name, FILE_SIZE)
    model = Architecture(base.model(), LABEL_COUNT).build()
    logger.info(model.summary(print_fn=lambda x: logger.info(x)))

    dataset = ImageDataSet(dataframe, "image_lien", "label", sample_count=SAMPLE_COUNT)
    dataset.load()
    dataset.find_n_top_labels(LABEL_COUNT)
    dataset.downsample_to_equal()
    train, valid = dataset.split_sample(0.2)

    gen = DataSetGenerator(base.preprocess_input_method())
    train_generator = gen.generator(
        "train",
        train,
        "input/images",
        target_size=FILE_SIZE,
        batch_size=BATCH_SIZE,
    )
    valid_generator = gen.generator(
        "valid",
        valid,
        "input/images",
        target_size=FILE_SIZE,
        batch_size=BATCH_SIZE,
    )

    client = Client(threads_per_worker=4, n_workers=4)

    trainer = Trainer(
        model,
        n_class=LABEL_COUNT,
        batch_size=BATCH_SIZE,
        target_file_size_shape=FILE_SIZE,
        logger=logger,
    )
    with joblib.parallel_backend("dask"):
        trainer.train(train_generator, valid_generator)
    trainer.save(model_output)


cli.add_command(predict_dataset)
cli.add_command(predict_folder)

cli.add_command(train_dataset)
cli.add_command(train_folder)

cli.add_command(env)


if __name__ == "__main__":
    cli()
